{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bad3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers datasets tqdm ipywidgets hf_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73824701",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch transformers datasets tqdm ipywidgets hf_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc33cc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a282d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "# device = torch.device(\"mps\")\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\", dtype=torch.float32)\n",
    "model.to(device)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\", use_fast=True)\n",
    "\n",
    "ds_load_name = [\"tanganke/dtd\", \"tanganke/eurosat\", \"tanganke/gtsrb\", \"ylecun/mnist\", \"tanganke/resisc45\", \"tanganke/stanford_cars\", \"tanganke/sun397\", \"ufldl-stanford/svhn\"]\n",
    "dataset_name = [\"DTD\", \"EuroSAT\", \"GTSRB\", \"MNIST\", \"RESISC45\", \"Stanford_Cars\", \"SUN397\", \"SVHN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(dataset_name):\n",
    "    if name == \"SVHN\":\n",
    "        ds = load_dataset(ds_load_name[i], \"cropped_digits\", cache_dir=\"/workspace/.hf_cache\")\n",
    "    else:\n",
    "        ds = load_dataset(ds_load_name[i], cache_dir=\"/workspace/.hf_cache\")\n",
    "\n",
    "    features = ds[\"train\"].features\n",
    "    label_names = features[\"label\"].names\n",
    "\n",
    "    def add_heading(sample):\n",
    "        label = f\"a photo of {label_names[sample[\"label\"]]}\"\n",
    "        sample[\"text\"] = label\n",
    "        return sample\n",
    "    \n",
    "    split = ds[\"train\"].train_test_split(train_size=0.8, seed=6)\n",
    "    train = split[\"train\"].map(add_heading)\n",
    "    val = split[\"test\"].map(add_heading)\n",
    "    test = ds[\"test\"]\n",
    "\n",
    "    train_dataset = train.map(lambda samples: processor(text=samples[\"text\"], images=samples[\"image\"], padding=\"max_length\", max_length=77, truncation=True, return_tensors=\"pt\"), batched=True)\n",
    "    val_dataset = val.map(lambda samples: processor(text=samples[\"text\"], images=samples[\"image\"], padding=\"max_length\", max_length=77, truncation=True, return_tensors=\"pt\"), batched=True)\n",
    "    test_dataset = test.map(lambda samples: processor(images=samples[\"image\"], return_tensors=\"pt\"), batched=True)\n",
    "\n",
    "    train_dataset = train_dataset.remove_columns([\"image\", \"text\"])\n",
    "    val_dataset = val_dataset.remove_columns([\"image\", \"text\"])\n",
    "    test_dataset = test_dataset.remove_columns([\"image\"])\n",
    "\n",
    "    train_dataset.save_to_disk(f\"data/{name}/train\")\n",
    "    val_dataset.save_to_disk(f\"data/{name}/val\")\n",
    "    test_dataset.save_to_disk(f\"data/{name}/test\")\n",
    "\n",
    "    features = ds[\"test\"].features\n",
    "    label_names = features[\"label\"].names\n",
    "    all_label_texts = [f\"a photo of {label}\" for label in label_names]\n",
    "    label_encodings = processor(text=all_label_texts, padding=\"max_length\", max_length=77, truncation=True, return_tensors=\"pt\")\n",
    "    label_input_ids = label_encodings.input_ids.to(device)\n",
    "    label_attention_mask = label_encodings.attention_mask.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        all_label_embeds = model.get_text_features(input_ids=label_input_ids, attention_mask=label_attention_mask)\n",
    "        all_label_embeds /= all_label_embeds.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    torch.save(all_label_embeds.cpu(), f\"data/{name}/all_label_embeds.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
